{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f596df-3170-477c-86d0-142aafa9178d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# __premod__ pipeline - main script file\n",
    "\n",
    "## Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da17017-104c-428b-aa7a-6303f9e7876d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, csv, pytesseract, re\n",
    "import lxml.etree as et\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import A_navigation as nav\n",
    "from utils import B_dl_iiif as dlpics\n",
    "from utils import C1_ocr_and_struct as docr\n",
    "from utils import C2_page_2_doc as valto\n",
    "from utils import D1_alto_2_tei as vtei\n",
    "from utils import D2_tei_2_ht as vht\n",
    "from utils import D3_ht_2_kw as vkw\n",
    "from utils import E_kw_2_table as vtab\n",
    "from utils import F_table_2_DB as vdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe49f537-3583-4a20-b960-1b3491a60e1d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## When starting a project, make the base project folder\n",
    "This function will enable you to have the correct architecture and naming straight away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424309f5-f67c-4355-996d-61235345bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"Bonjour !\"\n",
    "\n",
    "nav.new_project(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e4222-0684-48b7-a851-cfae0206b2fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## To download images from IIIF manifests\n",
    "\n",
    "If you wish to use steps 4 and 5, you will need a language model compatible with HOPS parser and write its location in the lg_models variable just below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb6f671-7f46-41b8-9069-a9d90c2e7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# à reprendre\n",
    "project = \"OBJECTive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ea438-0b9f-4df6-8d24-1502b045ce9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the output folder with a timestamp.\n",
    "dir_date = nav.mk_tmsp_dir(os.getcwd(), project=project)\n",
    "\n",
    "# Start the process.\n",
    "dlpics.dlpics(project, dir_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac26b30-c88a-4681-bb14-b209b780b92c",
   "metadata": {},
   "source": [
    "## To OCRize images with PyTesseract\n",
    "\n",
    "**Note**: For better results, we advise you use Kraken/eScriptorium or Pero OCR.\n",
    "\n",
    "Before this step, the `*_instructions.json` parameter files in each metadata folder must be filled to indicate the first and last page of the body of the text, as well as the number of structuration levels detected.\n",
    "\n",
    "Ex: If the document has parts and subparts, and the next level is the paragraph, there are 2 structuration levels. If the document has parts, chapters and subchapters, and the next level is the paragraph, the document has 3 structuration levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3b1be-5d3c-44d8-94ee-a5d86b4d2ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, csv, pytesseract, re\n",
    "import lxml.etree as et\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import C1_ocr_and_struct as docr\n",
    "from utils import D1_alto_2_tei as vtei\n",
    "\n",
    "project = \"OBJECTive\"\n",
    "\n",
    "dir_date = os.getcwd()+\"/output/OBJECTive/extraction_20241011_1446\"\n",
    "\n",
    "docr.pre_analysis(project, dir_date, OCRize = False, DataCat = False)\n",
    "#docr.img_to_alto(dir_date)\n",
    "#vtei.centralize_alto(dir_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3b29e1-4a9c-4a8d-802f-d5aed7722f1f",
   "metadata": {},
   "source": [
    "# To execute step n°4\n",
    "\n",
    "Before this step, the `*_separate_lines.csv` files of each document must be filled manually to indicate the paragraph breaks and titles.\n",
    "\n",
    "* __Note__: I have separated these two steps so one may change tokenization manually if needed. For instance, in case of numbered paragraphs, the numbers are not, per say, part of the sentence. Therefore, one may result to regular expressions to remove them from <tei:s> elements, so they cannot influence the syntactic analysis. However, if you have no such concerns with your corpus, you may execute the second as soon as the first is done.\n",
    "* If you need to modify the tokens, this must be done in the `*/working_data/recap/*_tokenized_tei.xml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ff5a4-d23c-4cb4-8f19-298c1454dc52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "struct.alto_to_struct(dir_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab647a8-b286-4a1d-986d-53d2bcc9f138",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please specify the folder containing your language model.\n",
    "\n",
    "lg_model = \"resources/lg_models/UD_French-Sequoia-flaubert\"\n",
    "\n",
    "# In case you have other references, you may put them in the resources directory\n",
    "# and specify the path here.\n",
    "\n",
    "presto = \"resources/dico_PRESTO_SIMPLE_05.05.23.dff\"\n",
    "corrtable = \"resources/MICLE_CorrTable_27-02-23.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6b929-f07e-4b44-af4a-eccb45a96a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, csv, pytesseract, re\n",
    "import lxml.etree as et\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import distant_ocr as docr\n",
    "from utils import struct_text as struct\n",
    "from utils import structd_2_ht as vht\n",
    "from utils import ht_to_info as vinf\n",
    "from utils import navigation as nav\n",
    "\n",
    "# Please specify the folder containing your language model.\n",
    "\n",
    "lg_model = \"resources/lg_models/UD_French-Sequoia-flaubert\"\n",
    "\n",
    "# In case you have other references, you may put them in the resources directory\n",
    "# and specify the path here.\n",
    "\n",
    "presto = \"resources/dico_PRESTO_SIMPLE_05.05.23.dff\"\n",
    "corrtable = \"resources/MICLE_CorrTable_27-02-23.csv\"\n",
    "dir_date = \"output/extraction_20240111_1510\"\n",
    "\n",
    "# REMETTRE CORRLANGUAGE SI NÉCESSAIRE\n",
    "# (Désactivé pour l'instant dans le .py.)\n",
    "vht.call_rzianes_ht_crisco(\n",
    "    dir_date,\n",
    "    lg_model,\n",
    "    vht.make_d_PRESTO(presto),\n",
    "    vht.make_d_CorrTable(corrtable),\n",
    "    corrlanguage=\"fr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32543d5b-8341-4d57-869c-0627a94987a8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, csv, pytesseract, re\n",
    "import lxml.etree as et\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import distant_ocr as docr\n",
    "from utils import struct_text as struct\n",
    "from utils import structd_2_ht as vht\n",
    "from utils import ht_to_info as vinf\n",
    "from utils import navigation as nav\n",
    "\n",
    "dir_date = \"output/extraction_20240111_1510\"\n",
    "project = \"OBJECTive\"\n",
    "vinf.kw_test(dir_date, f\"input/{project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ea63d-654f-4b72-8731-35b560131ff7",
   "metadata": {},
   "source": [
    "# To execute step n°4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc57d1-f2e1-477e-98b1-989861e81143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, csv, pytesseract, re\n",
    "import lxml.etree as et\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import distant_ocr as docr\n",
    "from utils import struct_text as struct\n",
    "from utils import structd_2_ht as vht\n",
    "from utils import ht_to_info as vinf\n",
    "from utils import navigation as nav\n",
    "\n",
    "dir_date = \"output/extraction_20240111_1510\"\n",
    "project = \"OBJECTive\"\n",
    "\n",
    "vinf.kw_to_table(dir_date, projet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ed315-e39b-4c39-84af-dfaec435fa64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17d29635-468b-4e46-9a8d-0a934aeda3f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb397bb-285d-402d-a10f-1c6dcb007369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
